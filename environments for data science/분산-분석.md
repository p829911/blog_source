---
title: 분산 분석
date: 2018-11-26 23:21:57
tags: Math
categories:
- Math
mathjax: true
---

이 포스트는 fastcampus에서 강의를 하고 계시는 김도형 박사님의 강의록을 따라 쓰며 연습한 포스트입니다.

[데이터 사이언스 스쿨](https://datascienceschool.net/view-notebook/661128713b654edc928ecb455a826b1d/)

![](/images/1543299373849.png)

선형회귀분석의 결과가 얼마나 좋은지는 단순히 잔차제곱합(RSS: Residual sum of square)으로 평가할 수 없다. 변수의 단위 즉, 스케일이 달라지면 회귀분석과 상관없이 잔차제곱합도 달라지기 때문이다.



분산 분석(ANOVA: Analysis of Variance)은 종속변수의 분산과 독립변수의 분산간의 관계를 사용하여 선형회귀분석의 성능을 평가하고자 하는 방법이다. 분산 분석은 서로 다른 두 개의 선형회귀분석의 성능 비교에 응용할 수 있으며 독립변수가 카테고리 변수인 경우 각 카테고리 값에 따른 영향을 정량적으로 분석하는데도 사용된다.



$\hat{y}$를 종속변수 $y$의 샘플 평균이라고 하자.
$$
\hat{y} = \frac{1}{N} \sum_{i=1}^N y_i
$$
**TSS (total sum of squares)**
$$
\text{TSS} = \sum_{i=1}^N (y_i-\hat{y})^2 = (y-\hat{y})^T(y-\hat{y})
$$
종속변수값의 움직임의 범위를 나타낸다.



**ESS(explained sum of squares)**
$$
\text{ESS} = \sum_{i=1}^N (\hat{y_i}-\bar{\hat{y}})^2 = (\hat{y}-\bar{\hat{y}})^T(\hat{y}-\bar{\hat{y}})
$$
회귀 분석에 의해 예측한 값 $\hat{y}$의 분산을 나타낸다.

모형에서 나온 예측값의 움직임의 범위를 뜻한다.



**RSS (residual sum of squares)**
$$
\text{RSS} = \sum_{i=1}^N(y_i-\hat{y_i})^2 = e^Te
$$
잔차 $e$의 분산을 나타낸다.

잔차의 움직임의 범위, 즉 오차의 크기를 뜻한다.



만약 회귀모형이 상수항을 포함하여 올바르게 정의되었다면 잔차의 평균이 0이 된다.

즉 종속변수의 평균과 모형 예측값의 평균이 같아진다.
$$
\bar{e} = \bar{y} - \bar{\hat{y}} = 0
$$

$$
\bar{y} = \bar{\hat{y}}
$$

그리고 이 분산값들 간에는 다음과 같은 관계가 성립한다.
$$
\text{TSS} = \text{ESS} + \text{RSS}
$$
위 식이 말하는 바는 다음과 같다.

> 모형 예측치의 움직임의 크기(분산)은 종속변수의 움직임의 크기(분산)보다 클 수 없다.
>
> 모형의 성능이 좋을 수록 모형 예측치의 움직임의 크기는 종속변수의 움직임의 크기와 비슷해진다.



example

```python
import numpy
import pandas
from sklearn.datasets import make_regression

x0, y, coef = make_regression(n_samples=100, n_features=1, noise=30, coef=True, random_state=0)
dfx0 = pd.DataFrame(x0, columns=["X"])
dfx = sm.add_constant(dfx0)
dfy = pd.DataFrame(y, columns=["Y"])
df = pd.concat([dfx, dfy], axis=1)

model = sm.OLS.from_formula("Y ~ X", data=df)
result = model.fit()
```

```python
print("TSS = ", result.uncentered_tss)
print("ESS = ", result.mse_model)
print("RSS = ", result.ssr)
print("ESS + RSS = ", result.mse_model + result.ssr)
print("R squared = ", result.rsquared)
```



**결정 계수(Coefficient of Determination)**

위의 분산 관계식에서 모형의 성능을 나타내는 결정계수(Coefficient of Determination) $R^2$를 정의할 수 있다.
$$
R^2 \equiv 1- \dfrac{\text{RSS}}{\text{TSS}} = \dfrac{\text{ESS}}{\text{TSS}}
$$
분산 관계식과 모든 분산값이 0보다 크다는 점을 이용하면 $R^2$의 값은 다음과 같은 조건을 만족한다.
$$
0 \leq R^2 \leq 1
$$
여기에서 $R^2$가 0 이라는 것은 오차의 분산 RSS가 최대이고 회귀분석 예측값의 분산 ESS가 0인 경우이므로 회귀분석 결과가 아무런 의미가 없다는 뜻이다. 반대로 $R^2$가 1이라는 것은 오차의 분산 RSS가 0이고 회귀분석 예측의 분산 ESS가 TSS와 같은 경우이므로 회귀분석 결과가 완벽하다는 뜻이다. 따라서 결정계수값은 회귀분석의 성능을 나타내는 수치라고 할 수 있다.



**분산 분석표**

분산 분석의 결과는 보통 다음과 같은 분산 분석표를 사용하여 표시한다. 아래의 표에서 $N$은 데이터의 갯수, $K$는 모수의 갯수를 뜻한다.

|   source   | degree of freedom |          sum of square           |               mean square               |        F test-statistics         | p-value |
| :--------: | :---------------: | :------------------------------: | :-------------------------------------: | :------------------------------: | :-----: |
| Regression |      $K -1$       |           $\text{ESS}$           | $s_\hat{y}^2 = \dfrac{\text{ESS}}{K-1}$ | $F = \dfrac{s_\hat{y}^2}{s_e^2}$ | p-value |
|  Residual  |      $N - K$      |           $\text{RSS}$           |    $s_e^2 = \dfrac{\text{RSS}}{N-K}$    |                                  |         |
|   Total    |      $N - 1$      |           $\text{TSS}$           |    $s_y^2 = \dfrac{\text{TSS}}{N-1}$    |                                  |         |
|   $R^2$    |                   | $\dfrac{\text{ESS}}{\text{TSS}}$ |                                         |                                  |         |



**결정 계수와  상관 계수**

$y$와 $\hat{y}$의 샘플 상관계수 $r$의 제곱은 결정 계수 $R^2$와 같다.



**상수항이 없는 모형의 경우**

모형에서 상수항을 지정하지 않은 경우에는 결정계수의 정의에 사용되는 TSS의 정의가 다음과 같이 달라진다.
$$
\text{TSS} = \sum_{i=1}^{N}y_i^2 = y^Ty
$$
즉, 실제 샘플평균과 상관없이 $\bar{y} = 0$ 이라는 가정하에 TSS를 계산한다.

이렇게 정의하지 않으면 TSS = RSS + ESS 관계식이 성립하지 않아서 결정계수의 값이 1보다 커지게 된다.

따라서 모형의 결정계수를 비교할 때 상수항이 없는 모형과 상수항이 있는 모형은 직접 비교하면 안된다.



**F 검정을 이용한 모형 비교**

F 검정을 이용하면 다음과 같이 포함관계에 있는 두 모형의 성능을 비교할 수 있다.

- 전체 모형(Full Model):
  $$
  y = w_0 + w_1x_1 + w_2x_2 + w_3x_3
  $$



- 축소 모형(Reduced Model):
  $$
  y = w_0 + w_1x_1
  $$



다음과 같은 귀무가설을 검정하는 것은 위의 두 모형이 실질적으로 같은 모형이라는 가설을 검정하는 것과 같다.
$$
H_0 : w_2 = w_3 = 0
$$
이 검정도 F검정을 사용하여 할 수 있다. StatsModels에서는 `anova_lm`명령에 두 모형의 result 객체를 인수로 넣어주면 이러한 검정을 할 수 있다. 인수를 넣어줄 때는 축소 모형(reduced model), 전체 모형(full model)의 순서로 넣어준다.